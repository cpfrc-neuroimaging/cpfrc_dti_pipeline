<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="ie ie6" lang="en"> <![endif]-->
<!--[if IE 7 ]><html class="ie ie7" lang="en"> <![endif]-->
<!--[if IE 8 ]><html class="ie ie8" lang="en"> <![endif]-->
<!--[if (gte IE 9)|!(IE)]><!-->
<html lang="en">
<!--<![endif]-->

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <meta name="keywords" content="">

    <title>CPFRC DTI Pipeline Documentation | University of Michigan</title>

    <link rel="shortcut icon" href="images/UM.ico" type="image/x-icon">

    <link rel="stylesheet" type="text/css" href="fonts/font-awesome-4.3.0/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="css/stroke.css">
    <link rel="stylesheet" type="text/css" href="css/bootstrap.css">
    <link rel="stylesheet" type="text/css" href="css/animate.css">
    <link rel="stylesheet" type="text/css" href="css/prettyPhoto.css">
    <link rel="stylesheet" type="text/css" href="css/style.css">

    <link rel="stylesheet" type="text/css" href="js/syntax-highlighter/styles/shCore.css" media="all">
    <link rel="stylesheet" type="text/css" href="js/syntax-highlighter/styles/shThemeRDark.css" media="all">

    <!-- CUSTOM -->
    <link rel="stylesheet" type="text/css" href="css/custom.css">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>
    <button onclick="topFunction()" id="myBtn" title="Go to top"><i class="fa fa-chevron-up" aria-hidden="true"></i></button>

    <script>
        var mybutton = document.getElementById("myBtn");
        window.onscroll = function() {scrollFunction()};
        function scrollFunction() {
            if (document.body.scrollTop > 1000 || document.documentElement.scrollTop > 1000) {
                mybutton.style.display = "block";
            } else {
                mybutton.style.display = "none";
            }
        }
        function topFunction() {
            window.scrollTo({ top: 0, behavior: 'smooth' })
            document.documentElement.scrollTo({ top: 0, behavior: 'smooth' })
        }

        document.addEventListener("DOMContentLoaded", () => {
            document.querySelector('#mode').addEventListener('click',()=>{
                document.querySelector('html').classList.toggle('dark');
            })
        });


    </script>

    <div id="wrapper">

        <div id="mode" >
            <div class="dark">
                <svg aria-hidden="true" viewBox="0 0 512 512">
                    <title>lightmode</title>
                    <path fill="currentColor" d="M256 160c-52.9 0-96 43.1-96 96s43.1 96 96 96 96-43.1 96-96-43.1-96-96-96zm246.4 80.5l-94.7-47.3 33.5-100.4c4.5-13.6-8.4-26.5-21.9-21.9l-100.4 33.5-47.4-94.8c-6.4-12.8-24.6-12.8-31 0l-47.3 94.7L92.7 70.8c-13.6-4.5-26.5 8.4-21.9 21.9l33.5 100.4-94.7 47.4c-12.8 6.4-12.8 24.6 0 31l94.7 47.3-33.5 100.5c-4.5 13.6 8.4 26.5 21.9 21.9l100.4-33.5 47.3 94.7c6.4 12.8 24.6 12.8 31 0l47.3-94.7 100.4 33.5c13.6 4.5 26.5-8.4 21.9-21.9l-33.5-100.4 94.7-47.3c13-6.5 13-24.7.2-31.1zm-155.9 106c-49.9 49.9-131.1 49.9-181 0-49.9-49.9-49.9-131.1 0-181 49.9-49.9 131.1-49.9 181 0 49.9 49.9 49.9 131.1 0 181z"></path>
                </svg>
            </div>
            <div class="light">
                <svg aria-hidden="true" viewBox="0 0 512 512">
                    <title>darkmode</title>
                    <path fill="currentColor" d="M283.211 512c78.962 0 151.079-35.925 198.857-94.792 7.068-8.708-.639-21.43-11.562-19.35-124.203 23.654-238.262-71.576-238.262-196.954 0-72.222 38.662-138.635 101.498-174.394 9.686-5.512 7.25-20.197-3.756-22.23A258.156 258.156 0 0 0 283.211 0c-141.309 0-256 114.511-256 256 0 141.309 114.511 256 256 256z"></path>
                </svg>
            </div>
        </div>

        <div class="container">

            <section id="top" class="section docs-heading">

                <div class="row">
                    <div class="col-md-12">
                        <div class="big-title text-center">
                            <h1>CPFRC DTI Pipeline | University of Michigan</h1>
                            <p class="lead">Documentation Version 1.0</p>
                        </div>
                        <!-- end title -->
                    </div>
                    <!-- end 12 -->
                </div>
                <!-- end row -->

                <hr>

            </section>
            <!-- end section -->

            <div class="row">

                <div class="col-md-3">
                    <nav class="docs-sidebar" data-spy="affix" data-offset-top="300" data-offset-bottom="200" role="navigation">
                        <ul class="nav">
                            <li><a href="#line1">Mrtrix and Data Organization</a></li>
                            <li><a href="#line2">Creating Fieldmaps</a>
                                <ul class="nav">
                                    <li><a href="#line2_1">Create Fieldmap Script</a></li>
                                    <li><a href="#line2_2">fslFMAP Script</a></li>
                                </ul>
                            </li>
                            <li><a href="#line3">Copy and Convert the Data</a></li>
                            <li><a href="#line4">DWI Denoise</a></li>
                            <li><a href="#line5">Working on Armis</a></li>
                            <li><a href="#line6">dwifslpreproc</a>
                                <ul class="nav">
                                    <li><a href="#line6_1">Sbatch Script</a></li>
                                    <li><a href="#line6_2">Job Script</a></li>
                                </ul>
                            </li>
                            <li><a href="#line7">Spherical Deconvolution</a></li>
                            <li><a href="#line8">Create Tissue Boundaries</a></li>
                            <li><a href="#line9">Freesurfer Recon-all</a></li>
                            <li><a href="#line10">Creating the Connectome</a></li>
                        </ul>
                    </nav >
                </div>
                <div class="col-md-9">
                    <section class="welcome">

                        <div class="row">
                            <div class="col-md-12 left-align">
                               <h2 class="dark-text">Introduction<hr></h2>
                                <div class="row">

                                    <div class="col-md-12 full">
                                        <div class="intro1">
                                            <ul>
                                                <li><strong>Item Name : </strong>DTI Pipeline Docs</li>
                                                <li><strong>Item Version : </strong> v 1.0</li>
                                                <li><strong>Author  : </strong>Daniel Asay</li>
                                            </ul>
                                        </div>

                                        <hr>
                                        <div>
                                            <p>This documentation aims to serve as a guide for using the CPFRC DTI pipeline. The steps include everything from starting with the raw data from the fMRI Lab to creating a connectome for invidual subjects. Our pipeline draws heavily from the tutorial by Andy Jahn which can be found <a href="https://andysbrainbook.readthedocs.io/en/latest/MRtrix/MRtrix_Introduction.html" target="_blank">here</a>. It has been modified for our computing environment and largely transposed into Python. That being said, most of what's found here is broadly applicable beyond the CPFRC computing environment. 
                                            </p>

                                            <h4>Software Requirements</h4>
                                            <p>You will need the following sofware packages to follow this pipeline:</p>
                                            <ol>
                                                <li>Python version >= 3.8 </li>
                                                <li>MRtrix version 3.0.3 (install <a href="https://mrtrix.readthedocs.io/en/latest/installation/before_install.html" target="_blank">instructions</a>)</li>
                                                <li>FSL version >= 6.0.0 (install <a href="https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/FslInstallation" target="_blank">instructions</a>)</li>
                                                <li>Freesurfer version >= 6.0 (install <a href="https://surfer.nmr.mgh.harvard.edu/fswiki/DownloadAndInstall" target="_blank">instructions</a>)</li>
                                                <li>ANTs (install <a href="http://stnava.github.io/ANTs/" target="_blank">instructions</a>)</li>
                                            </ol>
                                        </div>
                                    </div>

                                </div>
                                <!-- end row -->
                            </div>
                        </div>
                    </section>

                    <section id="line1" class="section">

                        <div class="row">
                            <div class="col-md-12 left-align">
                                <h2 class="dark-text">MRtrix and Data Organization<hr></h2>
                            </div>
                            <!-- end col -->
                        </div>
                        <!-- end row -->

                        <div class="row">
                            <div class="col-md-12">

                                <h4>MRtrix</h4>

                                <p>MRtrix is a software package developed with the goal of improving the analysis of diffusion weighted images using constrained spherical deconvolution as opposed to tensor-fitting techniques. This technique aims to address the problem of crossing fibers within voxels that can be a confound when fitting a tensor. In short, it's a program that will suite our needs nicely. Please note that MRtrix makes use of external software, such as FSL. 
                                </p>

                                <p>To use MRtrix both on the server and Armis, we will use the same commands: <strong>module load mrtrix</strong> and <strong>module load fsl/6.0.3</strong>. If you're working on the server the <strong>module list</strong> command should list mrtrix/3.0_RC3 and fsl/6.0.3 as loaded modules. If you're working on Armis, the loading of the fsl and cuda modules is actually baked into the <strong>module load mrtrix</strong> command, so you should see three modules including: fsl/6.0.5.1, cuda/10.2.89 and mrtrix/3.0.3 after running module load mrtrix. If you do not see all of these modules loaded, please connact Bennet Fauber at HITS (bennet@umich.edu).

                                </p>

                                <h4>Data Organization</h4>

                                <p>The organization of data may vary from project to project. Here I will describe what was used for the explosive sync study as of August 2022.
                                </p>

                                <p>All subejct data comes to us via the fMRI Lab on North Campus and ends up in a directory labeled 'raw'. 
                                    In each subject's directory, there are several files and directories. For our purposes here, we are only interested in the 'DTI' and 'anatomy' directories. Within the 'DTI' directory, we will find several files that we need for our analyses. We will talk specifically about those files in subsequent sections. The most important thing for now is that you have DTI data. <br>Within the anatomy directory, you will probably see several directories. We are interested in the 't1spgr_208sl' directory, which is where our subject's T1 data is stored. Within the 't1spgr_208sl' directory, locate the <strong>t1spgr_208sl.nii</strong> file. If you don't see it, look around in other directories and then contact Scott Peltier (spelt@med.umich.edu) from the fMRI Lab if necessary.
                                </p>

                                <p>Once you've verified that you have both DTI and anatomical data, go back to the main study directory. An example of this would be something like: /PROJECTS/REHARRIS/explosives Once there, create a directory called 'dtiProc'. This will be where all the processed DTI data will be stored. Within dtiProc, create a subs directory and a scripts directory. Within the subs directory, each subject's dti, antomical and fieldmap data will be stored. Don't worry about creating those directories manually, they will be done automatically later. The majority of the commands that we run on the server will be executed on data stored in dtiProc as to not corrupt the raw data. Within the scripts directory, feel free to copy the scripts from this documentation, make any necessary edits, and save them in your scripts directory.
                                </p>
                            

                    </section>
                    <!-- end section -->

                    <section id="line2" class="section">

                        <div class="row">
                            <div class="col-md-12 left-align">
                                <h2 class="dark-text">Creating Fieldmaps<hr></h2>
                            </div>
                            <!-- end col -->
                        </div>
                        <!-- end row -->


                        <p>Because of a recent update to the scanner software from GE, the first thing we have to do is create fieldmaps for each of our subjects. To do so, we will be using various fsl commands. In addition to creating fieldmaps for each subject, we also have to copy over the appropriate bval and bvec files. The bval and bvec files found in the 'DTI' folder are incorrect, so we will be using bval and bvec files originally from the ABCD study that have been modified for our needs. As a general rule, the number of lines in your bval and bvec files should match the number of volumes in your diffusion data. If you'd like to see an example of bval and bvec files, download <a href="abcd/abcd_example.zip" download="example">here</a>. The data from the explosive sync study has 104 volumes, so our bval and bvec files have been edited to match.
                        </p>

                        <p>Let's look at the first script below. This script will copy over the bvec and bval files that we've edited to the main 'DTI' directory and then create fieldmaps using a bash script (more on that later). You will need to edit lines 14 and 15 for your specific needs. The dtiProc directory should point to the new directory you created in the Data Organization section. The rawDir should point to the directory that contains all of your subjects' raw data. Line 16 can be left alone if you're working in the CPFRC environment, otherwise you want to change it to the name of the directory where each subject's diffusion lives. For example, any given subject in the rawDir may have several sub-directories including functional, anatomical and diffusion data. If the name of the diffusion data sub-directory is the same for each subject, change the value in line 16 accordingly.
                        </p>

                        <div class="row">
                            <div class="col-md-12">

                        <p id="line2_1">Now we will go function by function and discuss what is happening. You can download the script <a href="scripts/createFieldMap.py.zip" download="createFieldmap">here</a> if interested. The verifyModules function will check that the necessary software/modules for this script are loaded in the environment. In this case, it's just fsl. The bcolors class below it contains color variables that can be accessed as part of the verifyModules function. The getSubList function will create a list of subjects based on the rawDir variable. A subject will only be added to the list if they have a 'dti.nii' file in their 'DTI' directory. changeBVFiles will copy the edited bval and bvec files mentioned above to each subject's 'DTI' directory. You will need to edit lines 73 and 74 to point to the path where your bval and bvec files are stored. The createFieldmaps function is the core of the script. First, it will check if a fieldmap has already been created for the subject. If so, it will skip the processing step. If the subject doesn't have a fieldmap, the fslFMAP.sh script (found below) gets copied from the dtiProc/scripts directory to the individual subject directory. Once copied, it will be executed. After createFieldmaps processes each subject, the checkOutput function will go through each subject and check if the fieldmap was successfully created. You will receive a list of all (if any) subjects that did not run correctly.
                        </p>


                                <h4>Create Field Map Script</h4>
                            </div>
                        </div>

                                <pre class="brush: python">
                        ##### This script has functions that will:
# 1) generate a list of all the subjects that have been processed on new scanner software
# 2) copy over abcd bvec and bval files 
# 3) create fieldmaps using external fsl script
# 4) verify that the fieldmaps have been successfully created

import sys
import os
import shutil
import time


dtiProc = "/PROJECTS/REHARRIS/explosives/dtiProc"
rawDir = "/PROJECTS/REHARRIS/explosives/raw/"
niiPath = "/DTI"

# verify that all the necessary modules have been loaded

def verifyModules():
    print("Modules loaded:")
    os.system("module list")
    while True:
            loaded = input(f"\n{bcolors.WARNING}For this script, you need the fsl module loaded.\nIs it listed above? If so, type yes and hit enter. \nIf not, please type no and hit enter.\n{bcolors.ENDC}")
            if loaded == "yes" or loaded == "y" or loaded == "Yes" or loaded == "YES":
                print("great! running script...")
                break
            elif loaded == "no" or loaded == "n" or loaded == "No" or loaded == "NO":
                print("\nplease load fsl using the following command:\n")
                print("module load fsl/6.0.3\n")
                print("after loading the module, relaunch the script")
                sys.exit()

class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

# get a list of all the subjects that have been processed with the new software

def getSubList(rawDir):
    os.chdir(rawDir)
    subList = []
    for sub in os.listdir():
        os.chdir(sub)
        if os.path.isdir("DTI"):
            os.chdir("DTI")
            if os.path.isfile("dti.nii"):
                subList.append(sub)
        os.chdir(rawDir)
    return subList


## copies the abcd bvec and bval files

def changeBVFiles(rawDir, subList):
    os.chdir(rawDir)
    for sub in subList:
        os.chdir(sub + niiPath)
        if os.path.isfile("abcd_edit.bval") and os.path.isfile("abcd_edit.bvec"):
            print("abcd bval and bvec files have already been copied over for subject " + sub)
            time.sleep(.1)
            os.chdir(rawDir)
            continue
        else:
            print("copying abcd bval and bvec files for subject " + sub)
            shutil.copy("/home/dasay/diffusion/abcd_edit.bval", os.getcwd())
            shutil.copy("/home/dasay/diffusion/abcd_edit.bvec", os.getcwd())
        os.chdir(rawDir)

# creates fieldmaps for each subject


def createFieldmaps(rawDir, subList):
    os.chdir(rawDir)
    for sub in subList:
        os.chdir(sub + niiPath)
        if os.path.isfile("final_fieldmap.nii.gz"):
            print("fieldmap already exists for subject " + sub + "\nmoving to next subject...")
            time.sleep(.1)
            os.chdir(rawDir)
        else:
            print("creating fieldmap for subject " + sub + " ...")
            shutil.copy("/PROJECTS/REHARRIS/explosives/dtiProc/scripts/fslFMAP.sh", os.getcwd())
            os.system("bash fslFMAP.sh")
            os.chdir(rawDir)



def checkOutput(rawDir, subList):
    os.chdir(rawDir)
    badSubs = []
    for sub in subList:
        os.chdir(sub + niiPath)
        if os.path.isfile("final_fieldmap.nii.gz"):
            print("Fieldmap successfully created for subject " + sub)
            time.sleep(.1)
            os.chdir(rawDir)
        else:
            badSubs.append(sub)
            os.chdir(rawDir)
    print("No fieldmaps were created for the following subjects:\n" + str(badSubs) + "\nIf there are no subjects listed, then you're good!")

verifyModules()

subjects = getSubList(rawDir)

changeBVFiles(rawDir, subjects)

createFieldmaps(rawDir, subjects)

checkOutput(rawDir, subjects)

                                </pre>


                        <div class="row">
                            <div class="col-md-12">

                        <p id ="line2_2">The <a href = "scripts/fslFMAP.sh.zip" download="fslFMAP">bash script</a> below, named fslFMAP.sh, is being called by the python script above and will need to be saved somewhere on your machine before running the python script. Remember to edit the python script above on line 90 with the location of the script. You can probably tell that the python script largely serves as a wrapper for this bash script. Let's walk through the script and see what it's doing.
                        </p>

                        <p>First, we use <i>fslsplit</i> to create a .nii file for each of the volumes in the dti.nii data. Next, we use <i>fslmerge</i> to combine the reverse polarity .nii file and the first volume from the dti data. Make sure the fm_rev_pol.nii file is in each subject's 'DTI' directory; the script will fail without it. The fslsplit commmand generates a lot of unnecessary files, so we can clean that up using <i>rm dti_split*</i>. The following <i>fslroi</i> and <i>fslmerge</i> commands are padding the data for the topup command. For whatever reason, topup does not work with there are an odd number of slices, so we add one in here. With the data padded we're ready to run <i>topup</i>. When topup is done we will remove the padded slice with <i>fslsplit</i> and rename the output file to final_fieldmap.nii.gz. If all goes well, you should have a file named <strong>final_fieldmap.nii.gz</strong> for each of your subejcts.
                        </p>

                              </div>
                        </div>

                        <h4>fslFMAP Script</h4>

                        <pre class="brush: bash">
#!/bin/bash


# split the data into its respective volumes
echo 'Splitting Volumes...'
fslsplit dti.nii dti_split -t

# merge the rev pol data with slice 0
echo 'merging volumes...'
fslmerge -t FM_vols.nii fm_rev_pol.nii dti_split0000.nii

# clean up directory
rm dti_split*

# extract one slice
echo 'extracting slice...'
fslroi FM_vols.nii FM_oneslice.nii 0 -1 0 -1 0 1 0 -1 

# merge it to the data
echo 'merging into padded data...'
fslmerge -z FM_padded FM_oneslice FM_vols.nii

# run topup on FM_padded
echo 'running topup...'
topup --imain=FM_padded.nii --datain=datain.txt --config=b02b0.cnf --out=my_topup_results --iout=fieldmap_b0 --fout=calculated_fm

# get rid of last volume in fieldmap
echo 'removing last volume'
fslsplit fieldmap_b0.nii final_fieldmap -t
mv final_fieldmap0000.nii.gz final_fieldmap.nii.gz 
rm final_fieldmap0001.nii.gz

                        </pre>

                    </section>
                    <!-- end section -->

                    <section id="line3" class="section">

                        <div class="row">
                            <div class="col-md-12 left-align">
                                <h2 class="dark-text">Copy and Convert the Data<hr></h2>
                            </div>
                            <!-- end col -->
                        </div>
                        <!-- end row -->

                        <p>With our fieldmaps created we are ready to move forward with data processing. First, we will copy the data from the rawDir to the each subject's directory under dtiProc. MRtrix uses a special file extension called .mif, so we will have to convert our nii data to mif format after it has been copied. Download the script <a href="scripts/preproc01.py.zip" download="copyConvert">here</a>. The downloadable script contains code for both this section and the DWI Denoise section.
                        </p>

                        <p>The script starts off with the verifyModules function which ensures that both Mrtrix and AFNI have both been loaded into the environment. The getSubList function will create a list of subjects from the rawSubDir. A subject gets added to the list if they have both dti data and have had a fieldmap created for them. Next, makeSubDirs will take the list created from getSubList and create a directory for each subject with dti, fieldmaps and anatomy sub-directories.
                        </p>
                        <p>After the directories are created, the copyData function will copy over data for the 3 modalities. copyData makes use of the checkIfDataCopied helper method to check if the data for each modality has already been copied over. This is where the resample function comes in. This function will ensure that the fieldmap and dti data have the same dimensions. If they don't, it will cause problems in later processing steps. The output of this function will be 'new_fieldmap.nii'. Once the data finishes copying and has been resampled, the renameAndConvert and convert functions work in tandem to convert the dti and fieldmap data from nii to mif format. Notice that the <i>mrconvert</i> command on lines 133-136 add the bval and bvec files to the header of the output file with the -fslgrad option. Your final outputs should be <strong>run-01_dwi.mif</strong> and <strong>fieldmap.mif</strong>.
                        </p>

                        <pre class="brush: python">

                        ### This scripts has functions that will: 
# 1) copy nifti data from raw dir to dtiProc, including fieldmaps, dti and anatomy
# 2) label dti and fieldmap data as PA and AP, respectively
# 3) convert the data from nii to mif format and combine with its bvec and bval files
# 4) compare the number of volumes in mif file and bvec/bval files, all 3 should be equal

import shutil
import os
import subprocess
import pandas as pd
import nibabel as nib
import numpy as np
import time

rawSubDir = "/PROJECTS/REHARRIS/explosives/raw/"
subsDir = "/PROJECTS/REHARRIS/explosives/dtiProc/subs/"
rawPath = "/DTI"


def verifyModules():
    print("Modules loaded:")
    os.system("module list")
    while True:
            loaded = input(f"\n{bcolors.WARNING}For this script, you need the mrtrix module loaded.\nIs it listed above? If so, type yes and hit enter. \nIf not, please type no and hit enter.\n{bcolors.ENDC}")
            if loaded == "yes" or loaded == "y" or loaded == "Yes" or loaded == "YES":
                print("great! running script...")
                break
            elif loaded == "no" or loaded == "n" or loaded == "No" or loaded == "NO":
                print("\nplease load fsl using the following command:\n")
                print("module load mrtrix\n")
                print("after loading the module, relaunch the script")
                sys.exit()
 
class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'


# this function will create a list of subjects to process if their data was collected using the new scanner software AND createFieldMap.py has successfully run

def getSubList(rawSubDir):
    os.chdir(rawSubDir)
    subList = []
    for sub in os.listdir():
        os.chdir(sub)
        if os.path.isdir("DTI"):
            os.chdir("DTI")
            if os.path.isfile("dti.nii") and os.path.isfile("final_fieldmap.nii.gz"):
                subList.append(sub)
        os.chdir(rawSubDir)
    return subList


# this function will create a subject directory and dti, fieldmaps and anatomy sub-directories in the dtiProc/subs dir

def makeSubDirs(subDir, rawSubDir):
    for sub in getSubList(rawSubDir):
        os.chdir(subDir)
        if os.path.isdir(sub):
            continue
        else:
            os.makedirs(sub)
            os.chdir(sub)
            os.makedirs("dti")
            os.makedirs("fieldmaps")
            os.makedirs("anatomy")

# if subject data has not already been copied, this function will copy it over from raw to dtiProc

def copyData(subDir, rawSubDir, rawPath):
    print("Copying over raw data...")
    for sub in getSubList(rawSubDir):
        dataPath = rawSubDir + sub + rawPath
        newDtiPath = subDir + sub + "/dti"
        dataCopied = checkIfDataCopied(newDtiPath, sub, "dti")
        if dataCopied is False:
            dtiCopyList = ["/abcd_edit.bval", "/abcd_edit.bvec", "/dti.nii"]
            for file in dtiCopyList:
                source = dataPath + file
                destination = newDtiPath
                print("Copying " + file + " for subject " + sub)
                shutil.copy(source, destination)
        fieldmaps = rawSubDir + sub + rawPath
        newFieldmapPath = subDir + sub + "/fieldmaps"
        dataCopied = checkIfDataCopied(newFieldmapPath, sub, "fieldmap")
        if dataCopied is False:
            fmapCopyList = ["/final_fieldmap.nii.gz"]
            for file in fmapCopyList:
                source = fieldmaps + file
                destination = newFieldmapPath
                print("Copying " + file + " for subject " + sub)
                shutil.copy(source, destination)
        anatomical = rawSubDir + sub + "/anatomy/t1spgr_208sl"
        newAnatomyPath = subDir + sub + "/anatomy"
        dataCopied = checkIfDataCopied(newAnatomyPath, sub, "anatomical")
        if dataCopied is False:
            anatCopyList = ["/t1spgr_208sl.nii"]
            for file in anatCopyList:
                source = anatomical + file 
                destination = newAnatomyPath
                print("Copying " + file + " for subject " + sub)
                shutil.copy(source, destination)

# this function will check if the raw data for a given subject has already been copied from raw to dtiProc

def checkIfDataCopied(dataPath, sub, modality):
    os.chdir(dataPath)
    dirContents = os.listdir()
    if dirContents:
        print(str(modality) + " data already copied for subject: " + sub)
        return True
    else:
        return False

def resample(rawSubDir, subDir):
    for sub in getSubList(rawSubDir):
        print("Resampling the data for subject " + sub)
        dtiNiiPath = subDir + sub + "/dti/dti.nii"
        fieldmapPath = subDir + sub + "/fieldmaps"
        os.chdir(fieldmapPath)
        shutil.copy(dtiNiiPath, os.getcwd())
        resampleCommand = "3dresample -master dti.nii -prefix new_fieldmap.nii -input final_fieldmap.nii.gz"
        proc = subprocess.Popen(resampleCommand, shell=True, stdout=subprocess.PIPE)
        proc.wait()
        os.remove("dti.nii")
        time.sleep(.1)


# function will convert dti and fieldmap data from .nii to .mif format.

def convert(fieldmap, sub):
    if fieldmap is False:
        if os.path.isfile("already_converted.txt"):
            print("Dti files have already been combined and converted to .mif format for subject " + sub)
            return
        print("Converting dti files for subject: " + sub)
        convertToMif = f"""
            mrconvert \
            dti.nii \
            run-01_dwi.mif \
            -fslgrad abcd_edit.bvec abcd_edit.bval
        """
        proc1 = subprocess.Popen(convertToMif, shell=True, stdout=subprocess.PIPE)
        proc1.wait()
        subprocess.run(['touch', 'already_converted.txt'])
    else:
        if os.path.isfile("already_converted.txt"):
            print("Fmap files have already been combined and converted to .mif format for subject " + sub)
            return
        print("Converting fmap files for subject: " + sub)
        convertToMif = f"""
            mrconvert \
            new_fieldmap.nii \
            fieldmap.mif 
        """
        proc2 = subprocess.Popen(convertToMif, shell=True, stdout=subprocess.PIPE)
        proc2.wait()
        subprocess.run(['touch', 'already_converted.txt'])


# go into each subject directory and call convert() function

def renameAndConvert(subDir):
    print("Converting files from nii to mif format...")
    for sub in getSubList(rawSubDir):
        # Go into dti directory for the sub and convert data to .mif
        os.chdir(subDir)
        dtiData = sub + "/dti"
        os.chdir(dtiData)
        convert(False, sub) # False indicates not fieldmap data
        os.chdir(subDir)
        fmapData = sub + "/fieldmaps"
        os.chdir(fmapData)
        convert(True, sub) # True indicates fieldmap data

def runAll(subDir, rawSubDir, rawPath):
    verifyModules()
    makeSubDirs(subDir, rawSubDir)
    copyData(subDir, rawSubDir, rawPath)
    resample(rawSubDir, subDir)
    renameAndConvert(subDir)

runAll(subDir, rawSubDir, rawPath)


                        </pre>


                    </section>
                    <!-- end section -->

                    <section id="line4" class="section">

                        <div class="row">
                            <div class="col-md-12 left-align">
                                <h2 class="dark-text">DWI Denoise <hr></h2>
                            </div>
                            <!-- end col -->
                        </div>
                        <!-- end row -->

                        <div class="row">

                            <div class="col-md-12">
                                <p>With the data converted to mif format, we're ready to run the first pre-processing step: <i>dwidenoise</i>. The dwidenoise command creates a noise map estimation by running a principle components analysis (PCA). Read <a href="https://mrtrix.readthedocs.io/en/latest/reference/commands/dwidenoise.html" target="_blank">here</a> for a more in-depth explanation. 
                                </p>
                                <p>You will notice that the script below has the same preamble as the script in the Copy and Convert the Data section. You can combine these scripts into one or keep them separate. They've been split up here for readability. verifyModules and getSubList run first to make sure we've got our necessary software loaded and all the correct subjects queued for processing. Our dwiDenoise function will run the MRtrix <i>dwidenoise</i> on each subject while also utilizing the checkNoiseFile function to check if dwiDenoise has already been run on the subject. If it has, that subject will be skipped to avoid redundant processing. 
                                </p>
                                <p>Next, we get to the createB0 function. This function does several things for us. First, it will go into each subject directory in dtiProc and create a directory called 'combined'. The combined directory will serve as the host directory for several different data files that come from both the dti and fieldmap directories. The overall purpose of the createB0 function is to extract the b-values from both the reverse and primary phase encoded images and combine them into one file. You'll notice that I have the b-values extraction step commented out for the fieldmap (reverse phase encoded) data. In our case, since the fieldmap is just one volume, it is not necessary (or feasible) to do so. However, I've left the commands there as a reference for those who may be in a different situation. We extract the b-values using MRtrix's <i>dwiextract</i> and then comnbine the two files into a B0 image using MRtrix's <i>mrcat</i>. Our final output file should be <strong>b0_pair.mif</strong>. The fixZDir function serves a similar purpose to <i>fslmerge</i> a couple of sections ago. We will be running topup later on as a part of a preprocessing step, so we need to make sure the dimensions in the z direction are even. Here, we accomplish that by running <i>mrgrid</i> on our denoised data. Our output file will have the same name, run-01_den.mif, but you should see our z direction data go up by one when you run <i>mrinfo</i>.
                                </p>
                                <p>The final function for this section is fixDataStrides. This function may not be strictly necessary to run, but I've found it useful in the past. There may be instances where, somewhere during processing, the data strides information in the header of your diffusion data gets incorrectly edited. This function should fix that problem. I also use it as a chance to copy my bval and bvec files into the 'combined' directory. The fixDataStrides function simply uses MRtrix's <i>mrconvert</i> command to convert the data from mif to nii format, and then back to mif with the fslgrad option. You should only have to do this if the data strides in your data read as anything besides: [-1 2 3 4]. You can get this info by running <i>mrinfo</i> on your run-01_den.mif data. The runAll function will run all of the aforementioned functions.
                                </p>
                            </div>


                        <pre class="brush: python">

import sys
import os
import shutil
import time


dtiProc = "/PROJECTS/REHARRIS/explosives/dtiProc"
rawDir = "/PROJECTS/REHARRIS/explosives/raw/"
niiPath = "/DTI"

# verify that all the necessary modules have been loaded

def verifyModules():
    print("Modules loaded:")
    os.system("module list")
    while True:
            loaded = input(f"\n{bcolors.WARNING}For this script, you need the fsl module loaded.\nIs it listed above? If so, type yes and hit enter. \nIf not, please type no and hit enter.\n{bcolors.ENDC}")
            if loaded == "yes" or loaded == "y" or loaded == "Yes" or loaded == "YES":
                print("great! running script...")
                break
            elif loaded == "no" or loaded == "n" or loaded == "No" or loaded == "NO":
                print("\nplease load fsl using the following command:\n")
                print("module load fsl/6.0.3\n")
                print("after loading the module, relaunch the script")
                sys.exit()

class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

# get a list of all the subjects that have been processed with the new software

def getSubList(rawDir):
    os.chdir(rawDir)
    subList = []
    for sub in os.listdir():
        os.chdir(sub)
        if os.path.isdir("DTI"):
            os.chdir("DTI")
            if os.path.isfile("dti.nii"):
                subList.append(sub)
        os.chdir(rawDir)
    return subList


# run mrtrix function dwidenoise

def dwiDenoise(subDir):
    print("Running dwi_denoise on subjects...")
    for sub in getSubList(rawSubDir):
        dtiSubjectDir = subDir + sub + "/dti"
        os.chdir(dtiSubjectDir)
        if not checkNoiseFile(sub):
            print("Running on " + sub)
            denoise = "dwidenoise run-01_dwi.mif run-01_den.mif -noise noise.mif"
            proc = subprocess.Popen(denoise, shell=True, stdout=subprocess.PIPE)
            proc.wait()
        else:
            continue


def checkNoiseFile(sub):
    if os.path.isfile("run-01_den.mif"):
        print("dwi_denoise has already been run on subject: " + sub)
        return True
    else:
        return False

# this function will create a B0 image that combines the dti and fieldmap data 

def createB0(subDir):
    #Get b0 image
    for sub in getSubList(rawSubDir):
        currentSub = subDir + sub
        os.chdir(currentSub)
        if not os.path.isdir("combined"):
            os.makedirs("combined")
            combinedDir = os.getcwd() + "/combined"
            os.chdir("fieldmaps")
            shutil.copy("fieldmap.mif", combinedDir)
        print("Creating B0 image for subject: " + sub)
        # get mean for fmaps
        #os.chdir("fieldmaps")
        #fmapB0 = "mrconvert fieldmap.mif - | mrmath - mean meanReversed.mif -axis 3"
        #proc1 = subprocess.Popen(fmapB0, shell=True, stdout=subprocess.PIPE)
        #proc1.wait()
        #shutil.copy("meanReversed.mif", combinedDir)
        os.chdir(currentSub)
        # get mean for dti
        os.chdir("dti")
        dtiB0 = "dwiextract run-01_den.mif - -bzero | mrmath - mean meanPrimary.mif -axis 3"
        proc2 = subprocess.Popen(dtiB0, shell=True, stdout=subprocess.PIPE)
        proc2.wait()
        shutil.copy("meanPrimary.mif", combinedDir)
        shutil.copy("run-01_den.mif", combinedDir)
        # combine means into b0 image
        os.chdir(combinedDir)
        meanB0 = "mrcat fieldmap.mif meanPrimary.mif -axis 3 b0_pair.mif"
        proc3 = subprocess.Popen(meanB0, shell=True, stdout=subprocess.PIPE)
        proc3.wait()

#this function pads the data in the z direction so that there's not an uneven number for topup later on 
# during dwifslpreproc

def fixZDir(subDir):
    for sub in getSubList(rawSubDir):
        currentSub = subDir + sub + "/combined"
        os.chdir(currentSub)
        print("running mrgrid on subject " + sub)
        mrgrid = "mrgrid run-01_den.mif pad -axis 2 0,1 out.mif"
        proc1 = subprocess.Popen(mrgrid, shell=True, stdout=subprocess.PIPE)
        proc1.wait()
        os.remove("run-01_den.mif")
        rename = "mrconvert out.mif run-01_den.mif"
        proc2 = subprocess.Popen(rename, shell=True, stdout=subprocess.PIPE)
        proc2.wait()
        os.remove("out.mif")

def fixDataStrides(subDir):
    """
    This is to be run when the data strides read as anything else besides [-1 2 3 4]
    Use mrinfo to view data strides. This is a fix if dwifslpreproc does not run.
    """
    for sub in getSubList(rawSubDir):
        currentSub = subDir + sub + "/combined"
        os.chdir(currentSub)
        shutil.copy("/home/dasay/diffusion/abcd_edit.bval", os.getcwd())
        shutil.copy("/home/dasay/diffusion/abcd_edit.bvec", os.getcwd())
        mifToNii = "mrconvert run-01_den.mif tmp.nii"
        proc1 = subprocess.Popen(mifToNii, shell=True, stdout=subprocess.PIPE)
        proc1.wait()
        os.remove("run-01_den.mif")
        niiToMif = "mrconvert tmp.nii run-01_den.mif -fslgrad abcd_edit.bvec abcd_edit.bval"
        proc2 = subprocess.Popen(niiToMif, shell=True, stdout=subprocess.PIPE)
        proc2.wait()
        os.remove("tmp.nii")

def runAll(subDir, rawSubDir, rawPath):
    verifyModules()
    makeSubDirs(subDir, rawSubDir)
    copyData(subDir, rawSubDir, rawPath)
    dwiDenoise(subDir)
    createB0(subDir)
    fixDataStrides(subDir)


                        </pre>


                        </div>
                        <!-- end row -->

                    </section>
                    <!-- end section -->

                    <section id="line5" class="section">

                        <div class="row">
                            <div class="col-md-12 left-align">
                                <h2 class="dark-text">Working on Armis<hr></h2>
                            </div>
                            <!-- end col -->
                        </div>
                        <!-- end row -->

                        <div class="row">

                            <div class="col-md-12">
                                <p>None of the commands we've run so far have demanded very much computational power. However, several of the commands/steps from this point on will run much faster on a supercomputer or HPC cluster than on a personal or local machine. In the case of the CPFRC, we use a cluster called Armis, provided by the University of Michigan for HIPPA protected data. Luckily, Armis exists in a SLURM environment, so the majority of the content found in the following scripts can be used in other SLURM environments found outside of the University of Michigan.
                                </p>
                                <p>Connecting to Armis- First, you'll have to connect to the lab server (make sure you're connected to the <a href="https://hits.medicine.umich.edu/accounts-access/wifi-networks/vpn-remote-network-access" target="_blank">VPN</a>). You can do this via the command line, NoMachine or Windows Remote Desktop. Once logged in, you can connect to Armis via the command line or <a href="https://arc.umich.edu/open-ondemand/" target="_blank">Open OnDemand</a>. I will only describe the command line interface here. Execute <i>ssh armis2.arc-ts.umich.edu</i> from the command line and you'll be prompted to enter a password. This will be your Level One password. Next, you'll be prompted to select one of three 2-factor authentication options via Duo. I prefer to use the first option, which sends a notification to your phone for you to approve, but you can use whichever method you like. You should see a 'success' message if everything goes well. The <i>ssh</i> command above can be a bit tedious to type, so I would suggest creating an alias for it and adding it to your .bash_profile or .bashrc file. Read about creating aliases <a href="https://linuxize.com/post/how-to-create-bash-aliases/" target="_blank">here</a>.
                                </p>
                                <p>Let's head over to where the explosive sync data is being stored here on Armis. Cd into the explosive sync directory: <i>cd /scratch/seharte_root/seharte99/shared_data/expl</i>.You should see several different directories. Notice the scripts directory with sbatch and pipeline sub-directories. This is where all the scripts that we'll run on Armis are stored, including cluster submissions and head node scripts. The sbatch sub-directory has a sub-directory for each of the jobs we'll submit to Armis. I've found that organizing the scripts in this mannner proves helpful as job scripts start to pile up. That being said, feel free to organize your scripts however makes most sense to you. 
                                </p>
                                <p>
                                Cd to the dtiProc directory. The dtiProc directory on Armis will largely mirror the dtiProc/subs directory on the lab server. To avoid entering your Level One password dozens of times, I would suggest using the linux commmand <i>rsync</i> and copy the entire dtiProc/subs directory to your Armis dtiProc directory. First, cd into your dtiProc directory on Armis. You could use a command that looks something like this to pull the data:<br><strong>rsync -aruv user@aneshartelab-prod01.med.umich.edu:/PROJECTS/REHARRIS/explosives/dtiProc/subs/ .</strong> This make take a while to run, depending on the number of files you have and their size. Once your data has finished transferring, you're ready to move on to the next preprocessing step: dwifslpreproc. See you there!
                                </p>
                            </div>

                    </section>
                    <!-- end section -->

                    <section id="line6" class="section">

                        <div class="row">
                            <div class="col-md-12 left-align">
                                <h2 class="dark-text">dwifslpreproc<hr></h2>
                            </div>
                            <!-- end col -->
                        </div>
                        <!-- end row -->

                        <p>MRtrix's <i>dwifslpreproc</i> command is the finale of all the preprocessing we've done up to this point. This command uses a blend of MRtrix original data preprocessing techniques along with FSL's topup and eddy current correction. To speed up processing time, we'll submit a processing job to Armis for each of the subjects. Without greater computing power and parallelization, it would take a regular computer upwards of 65 hours to process 30 subjects. An HPC cluster cuts that down to less than an hour. Download both scripts from this section <a href="scripts/dwifslpreproc.zip" download="dwifslpreproc">here</a>.
                        </p>

                        <p id="line6_1">Lines 1-20 comprise what's known as the sbatch preamble. This is how you request resources from the cluster management system and tell them which account to bill. Enter your email address on line 4 to be notified when the jobs complete, fail or are cancelled. Make sure you enter the faculty member's account you're using on line 7. Next, the script will load the necessary modules. Luckily for us, the <i>module load mrtrix</i> command also loads FSL and CUDA, which are necessary for dwifslpreproc to run in an HPC environment. You can edit the USERNAME on line 30 to whatever you'd like, but it is not strictly necessary. You will need to edit the SOURCE_DIR variable on line 36 to contain the path to your project's "home" directory. Line 40 copies the data from the combined directory to the temporary BIDS directory. Lines 42-55 simply print out some information about the job being executed on Armis. Lines 65-69 contain the actual dwifslpreproc command that we're running. Once it's finished running, the output will be copied to a specified directory on line 75. If all goes well, you should have output data for all subjects at <i>/scratch/seharte_root/seharte99/shared_data/expl/dwifslpreproc</i>
                        </p>

                        <h4>Sbatch Script</h4>

                        <pre class="brush: bash">
#!/bin/bash

###SBATCH --job-name=$subject
#SBATCH --mail-user=youremail@example.com
#SBATCH --mail-type=END,FAIL

#SBATCH --account=FACULTY ACCOUNT
#SBATCH --partition=gpu

#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1

#SBATCH --gpus-per-task=4
#SBATCH --mem-per-gpu=8gb

#SBATCH --time=1:00:00
#SBATCH --export=ALL

#### End SBATCH preamble

module purge
module load mrtrix

my_job_header

# Set participant name
participant=$subject

# Create a local directory in which to work
TMPDIR=$(mktemp -d /tmp/USERNAME-dtiMrtrix3.XXXXXXXXX)
cd $TMPDIR
mkdir BIDS

# Set the names of the dwifslpreproc diretories. 

SOURCE_DIR=/scratch/seharte_root/seharte99/shared_data/expl
BIDS_DIR=$PWD/BIDS

# Get the needed BIDS data; print only the summary statistics from the copy
rsync -a --info=STATS /scratch/seharte_root/seharte99/shared_data/expl/explBIDS/$participant/combined/ ./BIDS

# Print some information about the run that might be useful
echo "#---------------------------------------------------------------------#"
echo "Running on           :  $(hostname -s)"
echo "Processor type       :  $(lscpu | grep 'Model name' | sed 's/[ \t][ ]*/ /g')"
echo "Assigned processors  :  $(cat /sys/fs/cgroup/cpuset/slurm/uid_${EUID}/job_${SLURM_JOBID}/cpuset.cpus)"
echo "Assigned memory nodes:  $(cat /sys/fs/cgroup/cpuset/slurm/uid_${EUID}/job_${SLURM_JOBID}/cpuset.mems)"
echo "======================================================================="
echo "/tmp space"
df -h /tmp
echo "======================================================================="
echo "Memory usage"
free
echo "#---------------------------------------------------------------------#"
echo


# Run it
source /etc/profile.d/http_proxy.sh

cd BIDS

#### dwipreproc command

dwifslpreproc run-01_den.mif run-01_den_preproc.mif \
    -nocleanup \
    -pe_dir PA \
    -rpe_pair -se_epi b0_pair.mif \
    -eddy_options " --slm=linear --data_is_shelled"


# Copy the results out for posterity
echo "Copying $OUTPUT_DIR/$participant to ${SOURCE_DIR}/dwifslpreproc"
mkdir -p ${SOURCE_DIR}/dwifslpreproc/${participant}
rsync -arv ${BIDS_DIR}/ ${SOURCE_DIR}/dwifslpreproc/${participant}

# Change out of the $TMPDIR and remove it
cd
rm -rf $TMPDIR


                        </pre>

                    <p id="line6_2">Running the script above requires the use of what's commonly called a job submit script. It's pretty simple to use, but there are a few key details that should not be overlooked. Take a look at the example below. We have a for-loop that's looping through a text file containing a list of all the subjects we want to run. Make sure that text file is in the same directory as your job script. You don't need to edit lines six or seven. On line eight, you need to tell the script where to spit out the log file. You also need to make sure the directory you point it to is created <i>before</i> you execute the job script. Finally, make sure you include the name of your sbatch script at the end of line eight. To execute this script, type <i>source submitdwifslpreproc.sh</i>. You should see several messages in the terminal indicating that your jobs were submitted to the cluster. You can check the status of your jobs by typing <i>squeue -u your_username</i> in the command window.
                    </p>

                    <h4>Job Script</h4>

                    <pre class="brush: bash">
#!/bin/bash

for subject in $(cat sublist.txt); do

        export subject
        echo "Submitting $subject"
        sbatch --job-name=$subject --output=/scratch/seharte_root/seharte99/shared_data/expl/job_output/$subject-%j.log dwifslpreprocSbatch.sh

done
                    </pre>

                    </section>
                    <!-- end section -->

                    <section id="line7" class="section">

                        <div class="row">
                            <div class="col-md-12 left-align">
                                <h2 class="dark-text">Spherical Deconvolution<hr></h2>


                            <p>Congratulations, you're done with preprocessing! Now we'll start getting into the core of our diffusion pipeline. We'll discuss Constrained Spherical Deconvolution (CSD) in this section. The general idea behind CSD is to create a basis function from each subject's data to determine the orientation of diffusion in each voxel. This estimation is largely based on the type of tissue found in a given voxel and is similar to the hemodynamic response function used in fMRI analyses. However, before getting into our CSD analysis, we will create a brain mask to speed up our processing time. The script below details the mask generation process along with a CSD analysis. Download it <a href="scripts/preproc02.py.zip" download="sphericalDeconvolution">here</a>. This script is pretty hefty, but it's not as bad as it might look. Almost half of the functions serve as helpers to other functions or to avoid extra, unnecessary processing. Let's dive in.
                            </p>

                            <p>A nice thing about this script is that it really only needs to be edited in one place: line seven. Update procDir to be equal to the path to your dtiProc directory. Now we'll go function by function and discuss a little bit of what's happening. The <i>checkIfCompleted</i> function will iterate through each subject's directory in the dtiProc directory and check if the final output file, <strong>wmfod_norm.mif</strong>, is present. If so, the script has already been run on that subject and will not be run again. The subject gets added to the noRunSubList array which gets passed to all subsequent functions. We've seen <i>verifyModules</i> in previous sections. We need MRtrix and ANTs loaded for this script to work. 
                            </p>

                            <p><i>dwibiascorrect</i> kicks off the mask creation portion of this script. The <i>dwibiascorrect</i> command from MRtrix removes inhomogeneities from the data in preparation to create our brain mask. <i>getSubListBiasCorrect</i> collects a list of subjects that have not already had dwibiascorrect run on them. If the command has already been executed and the output file exists, there's no reason to run it again. You'll notice that every MRtrix/ANTs command we run in this script has an accompanying getSubList function to make sure we're not re-doing any work. With inhomogeneities removed, we're ready to create the brain mask using <i>dwi2mask</i>. Creating a brain mask significantly reduces processing time by removing non-brain voxels from our analysis. The <i>getSubListDwiMask</i> function checks if a mask has already been created for our subjects.
                            </p>

                            <p>The <i>dwi2Response</i> function is the first step in our CSD analysis. This MRtrix command decomposes the diffusion signal into smaller fiber orientations, creating fiber orientation distributions (FODs) that are specific to each individual subject. The output for this function will be three .txt files, one for each tissue type. These files are estimates of the ammount of diffusion in each of the three orthogonal directions. The <i>getSubListDwiResponse</i> checks if each subject already has the output from dwi2response. Next, we come to the <i>dwi2Fod</i> function. This function takes the basis functions generated by the dwi2response command and applies them to the diffusion data. The output will be .mif images for each tissue type: white matter, gray matter and cerebrospinal fluid. Within <i>dwi2Fod</i> we'll also run <i>mrconvert</i> to combine all three tissue types into one image file. <i>getSubListDwiFod</i> checks if dwi2Fod has already been run.
                            <br>Finally, we arrive at <i>normalizeData</i>. This function is here just in case you decide to run group level analyses on your data. If not, you can omit this function. Similarly to its predecessors, <i>getSubListNormalize</i> checks if <i>normalizeData</i> has already been run on each subject.
                            </p>

                            <h4>Constrained Spherical Deconvolution Script</h4>


                            <pre class="brush: python">
import os
import subprocess
import sys


procDir = "/scratch/seharte_root/seharte99/shared_data/expl/dtiProc"


# This function will check if the script has already been run to completion previously

def checkIfCompleted(procDir):
    os.chdir(procDir)
    noRunSubList = []
    for sub in os.listdir(os.getcwd()):
        os.chdir(sub)
        if os.path.isfile("wmfod_norm.mif"):
            print("all steps have already been run on subject " + sub)
            noRunSubList.append(sub)
            os.chdir(procDir)
        os.chdir(procDir)
    return noRunSubList

# This function will check if the necessary modules have been loaded

def verifyModules():
    print("Modules loaded:")
    os.system("module list")
    while True:
            loaded = input("\nFor this script, you need the mrtrix and ANTs modules loaded.\nAre they listed above? If so, type yes and hit enter. \nIf not, please type no and hit enter.\n")
            if loaded == "yes" or loaded == "y" or loaded == "Yes" or loaded == "YES":
                print("great! running script...")
                break
            elif loaded == "no" or loaded == "n" or loaded == "No" or loaded == "NO":
                print("\nplease load mrtrix and ANTs using the following command:\n")
                print("module load mrtrix ANTs\n")
                print("after loading the modules, relaunch the script")
                sys.exit()

# runs dwibiascorrect on all subjects fed in with list

def dwibiascorrect(procDir, noRunList):
    for sub in getSubListBiasCorrect(procDir, noRunList):
        os.chdir(sub)
        print("running dwibiascorrect on subject " + sub + "...")
        dwibiascorrect = "dwibiascorrect ants run-01_den_preproc.mif run-01_den_preproc_unbiased.mif -bias bias.mif"
        proc1 = subprocess.Popen(dwibiascorrect, shell=True, stdout=subprocess.PIPE)
        proc1.wait()
        if os.path.isfile("run-01_den_preproc_unbiased.mif"):
            print("dwibiascorrect ran successfully for subject " + sub)
        else:
            print("dwibiascorrect did NOT run successfully for subject " + sub + ". please check")
        os.chdir(procDir)

# checks if dwibiascorrect has already been run on the given subjects

def getSubListBiasCorrect(procDir, noRunList):
    os.chdir(procDir)
    subList = []
    for sub in os.listdir(os.getcwd()):
        if sub in noRunList:
            continue
        os.chdir(sub)
        if os.path.isfile("run-01_den_preproc_unbiased.mif"):
            print("dwibiascorrect has already been run on subject " + sub + ". Moving to next subject...")
            os.chdir(procDir)
            continue
        else:
            subList.append(sub)
        os.chdir(procDir)
    return subList

# runs dwi2mask on all given subjects

def dwi2mask(procDir, noRunList):
    for sub in getSubListDwiMask(procDir, noRunList):
        os.chdir(sub)
        print("running dwi2mask on subject " + sub + "...")
        dwi2mask = "dwi2mask run-01_den_preproc_unbiased.mif mask.mif"
        proc1 = subprocess.Popen(dwi2mask, shell=True, stdout=subprocess.PIPE)
        proc1.wait()
        if os.path.isfile("mask.mif"):
            print("dwi2mask ran successfully for subject " + sub)
        else:
            print("dwi2mask did NOT run successfully for subject " + sub + ". please check")
        os.chdir(procDir)

# checks if dwi2mask has already been run on the given subjects

def getSubListDwiMask(procDir, noRunList):
    os.chdir(procDir)
    subList = []
    for sub in os.listdir(os.getcwd()):
        if sub in noRunList:
            continue
        os.chdir(sub)
        if os.path.isfile("mask.mif"):
            print("dwi2mask has already been run on subject " + sub + ". Moving to next subject...")
            os.chdir(procDir)
            continue
        else:
            subList.append(sub)
        os.chdir(procDir)
    return subList

# runs dwi2response command with dhollander algorithm on all given subjects

def dwi2Response(procDir, noRunList):
    for sub in getSubListDwiResponse(procDir, noRunList):
        os.chdir(sub)
        print("running dwi2response on subject " + sub + "...")
        dwi2response = "dwi2response dhollander run-01_den_preproc_unbiased.mif wm.txt gm.txt csf.txt -voxels voxels.mif"
        proc1 = subprocess.Popen(dwi2response, shell=True, stdout=subprocess.PIPE)
        proc1.wait()
        if os.path.isfile("wm.txt"):
            print("dwi2response ran successfully for subject " + sub)
        else:
            print("dwi2response did NOT run successfully for subject " + sub + ". please check")
        os.chdir(procDir)

# checks if dwi2response has already been run on the given subjects

def getSubListDwiResponse(procDir, noRunList):
    os.chdir(procDir)
    subList = []
    for sub in os.listdir(os.getcwd()):
        if sub in noRunList:
            continue
        os.chdir(sub)
        if os.path.isfile("wm.txt"):
            print("dwi2response has already been run on subject " + sub + ". Moving to next subject...")
            os.chdir(procDir)
            continue
        else:
            subList.append(sub)
        os.chdir(procDir)
    return subList

# runs dwi2fod command on all available subjects

def dwi2Fod(procDir, noRunList):
    for sub in getSubListDwiFod(procDir, noRunList):
        os.chdir(sub)
        print("running dwi2fod on subject " + sub + "...")
        dwi2Fod = "dwi2fod msmt_csd run-01_den_preproc_unbiased.mif -mask mask.mif wm.txt wmfod.mif gm.txt gmfod.mif csf.txt csffod.mif"
        proc1 = subprocess.Popen(dwi2Fod, shell=True, stdout=subprocess.PIPE)
        proc1.wait()
        if os.path.isfile("wmfod.mif"):
            print("dwi2Fod ran successfully for subject " + sub)
        else:
            print("dwi2Fod did NOT run successfully for subject " + sub + ". please check")
        print("combining fod data...")
        combineFod = "mrconvert -coord 3 0 wmfod.mif - | mrcat csffod.mif gmfod.mif - vf.mif"
        proc2 = subprocess.Popen(combineFod, shell=True, stdout=subprocess.PIPE)
        proc2.wait()
        if os.path.isfile("vf.mif"):
            print("sucessfully combined data.")
        else:
            print("data did not successfully combine for subject " + sub + ". please check")
        os.chdir(procDir)

# checks if dwi2fod has already been run on the given subjects

def getSubListDwiFod(procDir, noRunList):
    os.chdir(procDir)
    subList = []
    for sub in os.listdir(os.getcwd()):
        if sub in noRunList:
            continue
        os.chdir(sub)
        if os.path.isfile("vf.mif"):
            print("dwi2Fod has already been run on subject " + sub + ". Moving to next subject...")
            os.chdir(procDir)
            continue
        else:
            subList.append(sub)
        os.chdir(procDir)
    return subList

# runs mtnormalise command on all available subjects

def normalizeData(procDir, noRunList):
    for sub in getSubListNormalize(procDir, noRunList):
        os.chdir(sub)
        print("running normalization on subject " + sub + "...")
        normalize = "mtnormalise wmfod.mif wmfod_norm.mif gmfod.mif gmfod_norm.mif csffod.mif csffod_norm.mif -mask mask.mif"
        proc1 = subprocess.Popen(normalize, shell=True, stdout=subprocess.PIPE)
        proc1.wait()
        if os.path.isfile("wmfod_norm.mif"):
            print("normalization ran successfully for subject " + sub)
        else:
            print("normalization did NOT run successfully for subject " + sub + ". please check")
        os.chdir(procDir)

# checks if mtnormalise has already been run on the given subjects

def getSubListNormalize(procDir, noRunList):
    os.chdir(procDir)
    subList = []
    for sub in os.listdir(os.getcwd()):
        if sub in noRunList:
            continue
        os.chdir(sub)
        if os.path.isfile("wmfod_norm.mif"):
            print("normalization has already been run on subject " + sub + ". Moving to next subject...")
            os.chdir(procDir)
            continue
        else:
            subList.append(sub)
        os.chdir(procDir)
    return subList

# execute all the functions in this order

verifyModules()
checkIfCompleted(procDir)
noRunList = checkIfCompleted(procDir)
dwibiascorrect(procDir, noRunList)
dwi2mask(procDir, noRunList)
dwi2Response(procDir, noRunList)
dwi2Fod(procDir, noRunList)
normalizeData(procDir, noRunList)

                            </pre>

                            </div>
                            <!-- end col -->
                        </div>
                        <!-- end row -->

                    </section>
                    <!-- end section -->

                    <section id="line8" class="section">

                        <div class="row">
                            <div class="col-md-12 left-align">
                                <h2 class="dark-text">Create Tissue Boundaries<hr></h2>
                            </div>
                            <!-- end col -->
                        </div>
                        <!-- end row -->

                        <div class="row">
                            <div class="col-md-6">
                                <strong>Included Stylesheets</strong>

                                <p>These are the primary CSS files used for general front-end styling. Use these to customize your theme even further. All included JavaScript codes under <strong>yourthemename/css/</strong></p>

                                <ul>
                                    <li>1. style.css - Primary stylesheet</li>
                                    <li>2. bootstrap.css - Bootstrap stylesheet</li>
                                    <li>3. owl-carousel.css - OWL Carousel</li>
                                    <li>4. fontawesome.css - FontAwesome Font Icons stylesheet</li>
                                    <li>5. custom.css - Pathos Color Schemes stylesheet</li>
                                    <li>6. prettyPhoto.css - Lightbox effect css file</li>
                                    <li>7. flexslider.css - Flexslider css file</li>
                                    <li>8. et-line.css - Elegant icons css file</li>
                                    <li>9. carousel.css - OWL Carousel css file</li>
                                    <li>10. animate.css - CSS3 animations css file</li>
                                </ul>

                            </div>

                            <div class="col-md-6">
                                <strong>Included JavaScript</strong>

                                <p>These are the various attribution inks to the Javascript files included or modified to work with in this theme. All included JavaScript codes under <strong>yourthemename/js/</strong></p>

                                <ul>
                                    <li>1. bootstrap.js - Bootstrap JavaScript</li>
                                    <li>2. custom.js - All JavaScript Plugins</li>
                                    <li>3. retina.js - Retina JavaScript</li>
                                    <li>4. jquery.js - Base JavaScript</li>
                                    <li>5. prettyPhoto.js - Lightbox JavaScript</li>
                                    <li>6. owl-carousel.js - Lightbox JavaScript</li>
                                    <li>7. revslider.js - Revolution Slider JavaScript</li>
                                    <li>8. flexslider.js - Flexslider JavaScript</li>
                                    <li>9. awesome-grid.nin.js - Awesome grid portfolio JavaScript</li>
                                    <li>10. circle.js - Coming soon page JavaScript</li>
                                    <li>11. contact.js - Contact form validate JavaScript</li>
                                    <li>12. isotope.js - Masonry Portfolio JavaScript</li>
                                    <li>13. progress.js - Progress bar JavaScript</li>
                                    <li>14. rotate.js - Text rotate effect JavaScript</li>
                                    <li>15. wow.js - CSS3 animation JavaScript</li>
                                </ul>
                            </div>
                        </div>
                        <!-- end row -->

                    </section>
                    <!-- end section -->

                    <section id="line9" class="section">

                        <div class="row">
                            <div class="col-md-12 left-align">
                                <h2 class="dark-text">Freesurfer Recon-all<hr></h2>
                            </div>
                            <!-- end col -->
                        </div>
                        <!-- end row -->

                        <div class="row">
                            <div class="col-md-12">

                                <p>You can find the version history (changelog.txt) file on <strong>yourthemename-full.zip</strong> folder or you can check changelog on theme sale page.</p>
                                <p>Once again, thank you so much for purchasing this theme. As I said at the beginning, I'd be glad to help you if you have any questions relating to this theme. No guarantees, but I'll do my best to assist. If you have a more general question relating to the themes on ThemeForest, you might consider visiting the forums and asking your question in the "Item Discussion" section.</p>

                                <hr>

                                <h4>Changelog</h4>

                                <pre class="brush: html">

                                        -----------------------------------------------------------------------------------------
                                        Version 3.8.4 - May 7th, 2015
                                        -----------------------------------------------------------------------------------------

                                        - new revolution slider plugin version
                                        - fixed security issue with xss vulnerability
                                        - improved demo importer for certain server environments
                                        - updated WooCommerce template files for the outdated message in system status
                                        - added suhosin check in system status 
                                        - added information that explains ZipArchive is required on your server for importing demos 
                                        - portfolio Grid template improvement
                                        - added more information to demo popup message for individual demo requirements
                                        - RTL style improvements
                                        - breadcrumb function improved for various areas

                                        -----------------------------------------------------------------------------------------
                                        Version 3.8.3 - May 7th, 2015
                                        -----------------------------------------------------------------------------------------
                                        - fixed responsive / retina issue for larger logos
                                        - fusion slider now uses responsive headings all the time
                                        - dropped custom Avada styles for select boxes in IE since it is not supported
                                        - fixed compatibility issue with Category Order and Taxonomy Terms Order plugin
                                        - fixed issue of full width background being affected by padding options
                                        - tested and fixed hellobar issue 
                                        - typography settings now apply to single post pages
                                        - improved smooth scroll in certain situations
                                        - youtube & vimeo videos will show at normal size in light box as long as video embed link is not used
                                        - fixed issue of â€œfixedâ€ featured image mode not working for carousels / recent work
                                        - fixed issue of header tagline font not working with font options

                                        -----------------------------------------------------------------------------------------
                                        Version 3.8.2 - May 7th, 2015
                                        -----------------------------------------------------------------------------------------
                                        - fixed formatting issues with Turkish language files 
                                        - letter spacing menu option improvement
                                        - improved fusion slider max content width setting
                                        - removed the â€œdisable first featured image on productsâ€ setting since it does not apply
                                        - improved portfolio featured image loading
                                        - removed encoding from tracking code, space before head, space before body, and custom CSS to stop it from parsing code within TO and removing special characters e.g. +
                                        - woo login box now shows login fields for logged out users
                                        - woo cart / my account links now show on mobile 
                                        - fixed button styling issue with gravity forms


                                      </pre>

                            </div>
                        </div>
                        <!-- end row -->

                    </section>
                    <!-- end section -->

                    <section id="line10" class="section">

                        <div class="row">
                            <div class="col-md-12 left-align">
                                <h2 class="dark-text">Creating the Connectome<hr></h2>
                            </div>
                            <!-- end col -->
                        </div>
                        <!-- end row -->

                        <div class="row">
                            <div class="col-md-12">
                                
                                <p>Code released under the <a href="#" target="_blank">Un License</a> License.</p>                        
                                <p>For more information about copyright and license check <a href=" https://choosealicense.com/licenses/unlicense/" target="_blank">choosealicense.com</a>.</p>
                            
                            </div>
                        </div>
                        <!-- end row -->

                    </section>
                    <!-- end section -->
                </div>
                <!-- // end .col -->

            </div>
            <!-- // end .row -->

        </div>
        <!-- // end container -->

    </div>
    <!-- end wrapper -->

    <script src="js/jquery.min.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/retina.js"></script>
    <script src="js/jquery.fitvids.js"></script>
    <script src="js/wow.js"></script>
    <script src="js/jquery.prettyPhoto.js"></script>

    <!-- CUSTOM PLUGINS -->
    <script src="js/custom.js"></script>
    <script src="js/main.js"></script>

    <script src="js/syntax-highlighter/scripts/shCore.js"></script>
    <script src="js/syntax-highlighter/scripts/shBrushXml.js"></script>
    <script src="js/syntax-highlighter/scripts/shBrushCss.js"></script>
    <script src="js/syntax-highlighter/scripts/shBrushJScript.js"></script>
    <script src="js/syntax-highlighter/scripts/shBrushPython.js"></script>
    <script src="js/syntax-highlighter/scripts/shBrushBash.js"></script>

</body>

</html>
